{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "     -------------------------------------- 260.1/260.1 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.2.1)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.4.0)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.7-cp310-cp310-win_amd64.whl (184 kB)\n",
      "     ------------------------------------- 184.6/184.6 kB 10.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.56.4)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\yatha\\appdata\\roaming\\python\\python310\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\yatha\\appdata\\roaming\\python\\python310\\site-packages (from lazy-loader>=0.1->librosa) (23.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (65.6.3)\n",
      "Requirement already satisfied: appdirs in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.28.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yatha\\appdata\\roaming\\python\\python310\\site-packages (from requests->pooch>=1.1->librosa) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (3.4)\n",
      "Installing collected packages: soxr, lazy-loader, audioread, soundfile, librosa\n",
      "Successfully installed audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2.post1 soundfile-0.12.1 soxr-0.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xuublh9ZjVLT"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1109088592.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install -q Kaggle\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# install Kaggle\n",
    "pip install -q Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9nNrpP-wj7QQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n"
     ]
    }
   ],
   "source": [
    "# create a kaggle folder\n",
    "! mkdir ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBpTJ-ELkCrp",
    "outputId": "14e5d2be-5231-4e0f-b903-1ca5dba93f5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSbzPBuqkF2x",
    "outputId": "03424b7b-d710-467d-f848-9cfe8af10a61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find either toronto-emotional-speech-set-tess.zip or toronto-emotional-speech-set-tess.zip.zip.\n"
     ]
    }
   ],
   "source": [
    "!unzip toronto-emotional-speech-set-tess.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3zos6C7FkQrx"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTpPh6qfldB4",
    "outputId": "9e4a05f4-f5a6-4302-fbba-e9e8473bd7fc"
   },
   "outputs": [],
   "source": [
    "paths =[]\n",
    "labels = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('/content/tess toronto emotional speech set data'):\n",
    "    for filename in filenames:\n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        label = filename.split('_')[-1]\n",
    "        label = label.split('.')[0]\n",
    "        labels.append(label.lower())\n",
    "    if len(paths) == 2800:\n",
    "        break\n",
    "print('Dataset is loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nmu7aB8evUA",
    "outputId": "4ca45b73-b29b-49cf-8e5e-03aaf144234b"
   },
   "outputs": [],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpzqlmXKex2V",
    "outputId": "edf6b80b-68d8-4dd9-c96a-312d1c5f4aa1"
   },
   "outputs": [],
   "source": [
    "paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZLFTGAwrcQpI",
    "outputId": "7d700103-b98a-45ef-b6d9-8da2671f641c"
   },
   "outputs": [],
   "source": [
    "## Create a dataframe\n",
    "df = pd.DataFrame()\n",
    "df['speech'] = paths\n",
    "df['label'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyRFe0kQdZF8",
    "outputId": "208c5e5e-4353-4c95-cc3e-31fb59c76557"
   },
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N718J1hldb_r"
   },
   "outputs": [],
   "source": [
    "df['label_count']= df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "w5chGs5zgaLS",
    "outputId": "acb14cd6-7c69-4858-939e-4c432461a536"
   },
   "outputs": [],
   "source": [
    "df.drop('label_count',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLnqn-dGdhbU",
    "outputId": "ca56bbbd-015e-4c04-d384-1008f1d9be73"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "rpNbbGA5dk5s",
    "outputId": "c13c1453-4a49-453d-821d-003ea724311a"
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "VijX8K50do-6",
    "outputId": "b4859ef7-a86c-4b02-88dc-93a846a0039e"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQTS5pcNdskT"
   },
   "outputs": [],
   "source": [
    "def waveplot(data, sr, emotion):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(emotion, size=20)\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def spectogram(data, sr, emotion):\n",
    "    x = librosa.stft(data)\n",
    "    xdb = librosa.amplitude_to_db(abs(x))\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.title(emotion, size=20)\n",
    "    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5kKG2Twlbyh",
    "outputId": "0ea3fb27-f7f1-4585-8eed-662d755cdd62"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfBREH2sldAg"
   },
   "outputs": [],
   "source": [
    "df.drop('label_count', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-8m4dpTnSK6",
    "outputId": "018dc5e9-8272-4526-f574-6a640528b696"
   },
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVAa3sHMnV8D",
    "outputId": "a69a8c82-3356-4095-a542-8b19640e0634"
   },
   "outputs": [],
   "source": [
    "df['speech'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "ZDv_Hft8nY_F",
    "outputId": "7aee8ca2-46b6-42b8-824b-90c822aa1075"
   },
   "outputs": [],
   "source": [
    "emotion = 'fear'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "jaJ0EPL2nd9A",
    "outputId": "23ccf984-3a54-4a81-d68f-dfb49bd7d050"
   },
   "outputs": [],
   "source": [
    "emotion = 'angry'\n",
    "path = np.array(df['speech'][df['label']==emotion])[1]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "eKMKl0P-noIR",
    "outputId": "3282d54f-acf3-45cc-ecda-34f02a24e04e"
   },
   "outputs": [],
   "source": [
    "emotion = 'disgust'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "-doQeZwynvb8",
    "outputId": "edc6eb1f-846a-471d-d50f-d800aa8b5ad8"
   },
   "outputs": [],
   "source": [
    "emotion = 'neutral'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "HgDzVwTUnyzn",
    "outputId": "54c9fbe7-ad09-4bca-e426-51e04d21cd1a"
   },
   "outputs": [],
   "source": [
    "emotion = 'sad'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "TSvoqov5xjGJ",
    "outputId": "38111382-4a32-4ea1-9417-48b741b484bd"
   },
   "outputs": [],
   "source": [
    "emotion = 'ps'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "tarIgxZQxl1v",
    "outputId": "af21a073-d0c8-4971-b314-eb01491899ef"
   },
   "outputs": [],
   "source": [
    "emotion = 'happy'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPpRmqgKx3Fa"
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37KjFnpaxrYx"
   },
   "outputs": [],
   "source": [
    "def extract_mfcc(filename):\n",
    "  y, sr = librosa.load(filename, duration=3, offset= 0.5)\n",
    "  mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "  return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvE0Z9eayi1E",
    "outputId": "df1db3bd-901f-41f9-edf9-3521f09affa9"
   },
   "outputs": [],
   "source": [
    "extract_mfcc(df['speech'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9xPB7rKyrPx"
   },
   "outputs": [],
   "source": [
    "X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRB02dVldNBx",
    "outputId": "72f01fba-f20d-4195-8b8e-375ea1d30872"
   },
   "outputs": [],
   "source": [
    "X_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1dxbXjVdSU3",
    "outputId": "23bfe267-fba8-4be8-96b4-0343e76059ff"
   },
   "outputs": [],
   "source": [
    "X = [x for x in X_mfcc]\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SInm1Wmwdgou",
    "outputId": "8e5062d8-416c-441d-bfbe-497d2c0dcc5d"
   },
   "outputs": [],
   "source": [
    "X = np.expand_dims(X, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fy8A1j3dq60"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder()\n",
    "y= enc.fit_transform(df[[\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8n6RFZHePFw"
   },
   "outputs": [],
   "source": [
    "y=y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7ofqDO_eSZa",
    "outputId": "64214c08-3a04-4c45-dd15-98fc588fc9c5"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovkUJSZKeU5-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_k4yYI7teqdv",
    "outputId": "5416cc65-0927-4fc4-d4cd-111c72b4644f"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM (256, return_sequences=False, input_shape=(40, 1)),\n",
    "    Dropout (0.5), #Add dropout after LSTA layer\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout (0.5), #Add dropout after dense layer\n",
    "    Dense (64, activation = 'relu'),\n",
    "    Dropout (0.5), #Add dropout after dense Layer\n",
    "    Dense(7, activation = 'softmax') ,\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "Model: \"Sequential\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yfWxojyer0V",
    "outputId": "df7c0449-ad5f-42bf-d9d2-450b09eb166d"
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=30,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
